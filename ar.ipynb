{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'INTER_AREA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\xampp\\htdocs\\FDS\\stage\\VENISE\\project\\ar.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/xampp/htdocs/FDS/stage/VENISE/project/ar.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/xampp/htdocs/FDS/stage/VENISE/project/ar.ipynb#ch0000000?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/xampp/htdocs/FDS/stage/VENISE/project/ar.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mimutils\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/xampp/htdocs/FDS/stage/VENISE/project/ar.ipynb#ch0000000?line=4'>5</a>\u001b[0m \u001b[39m# function to detect ArUco Markers\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/xampp/htdocs/FDS/stage/VENISE/project/ar.ipynb#ch0000000?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfindArucoMarkers\u001b[39m(img, markerSize \u001b[39m=\u001b[39m \u001b[39m6\u001b[39m, totalMarkers\u001b[39m=\u001b[39m\u001b[39m250\u001b[39m, draw\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Marwa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imutils\\__init__.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.5.4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[39m# import the necessary packages\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconvenience\u001b[39;00m \u001b[39mimport\u001b[39;00m translate\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconvenience\u001b[39;00m \u001b[39mimport\u001b[39;00m rotate\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconvenience\u001b[39;00m \u001b[39mimport\u001b[39;00m rotate_bound\n",
      "File \u001b[1;32mc:\\Users\\Marwa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imutils\\convenience.py:65\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[39m# perform the actual rotation and return the image\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[39mreturn\u001b[39;00m cv2\u001b[39m.\u001b[39mwarpAffine(image, M, (nW, nH))\n\u001b[1;32m---> 65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresize\u001b[39m(image, width\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, height\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, inter\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39;49mINTER_AREA):\n\u001b[0;32m     66\u001b[0m     \u001b[39m# initialize the dimensions of the image to be resized and\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[39m# grab the image size\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     dim \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     (h, w) \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mshape[:\u001b[39m2\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'INTER_AREA'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "\n",
    "# function to detect ArUco Markers\n",
    "def findArucoMarkers(img, markerSize = 6, totalMarkers=250, draw=True):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    key = getattr(cv2.aruco, f'DICT_{markerSize}X{markerSize}_{totalMarkers}')\n",
    "    \n",
    "    \n",
    "    #Load the dictionary that was used to generate the markers.\n",
    "    arucoDict = cv2.aruco.Dictionary_get(key)\n",
    "    \n",
    "    # Initialize the detector parameters using default values\n",
    "    arucoParam = cv2.aruco.DetectorParameters_create()\n",
    "    \n",
    "    # Detect the markers\n",
    "    bboxs, ids, rejected = cv2.aruco.detectMarkers(gray, arucoDict, parameters = arucoParam)\n",
    "    return bboxs, ids\n",
    "    \n",
    "# Superimposing the image on the aruco markers detected in the video \n",
    "imgH=480\n",
    "imgW=640\n",
    "\n",
    "video = cv2. VideoCapture(0)\n",
    "\n",
    "ret, video_frame=video.read()\n",
    "image = cv2.imread(r'nature.png')\n",
    "image = cv2.resize(image, (imgH, imgW))\n",
    "\n",
    "while(video.isOpened()):\n",
    "    if ret==True:\n",
    "        refPts=[]  \n",
    "        #Detect the Aruco markers on the video frame\n",
    "        arucofound =findArucoMarkers(video_frame, totalMarkers=100)\n",
    "        h, w = video_frame.shape[:2]\n",
    "        \n",
    "        # if the aruco markers are detected\n",
    "        if  len(arucofound[0])!=0:\n",
    "                \n",
    "                for Corner, id in zip(arucofound[0], arucofound[1]):\n",
    "                    \n",
    "                    corners = Corner.reshape((4, 2))\n",
    "                    (topLeft, topRight, bottomRight, bottomLeft) = corners\n",
    "                    topRight = (int(topRight[0]), int(topRight[1]))\n",
    "                    bottomRight = (int(bottomRight[0]), int(bottomRight[1]))\n",
    "                    bottomLeft = (int(bottomLeft[0]), int(bottomLeft[1]))\n",
    "                    topLeft = (int(topLeft[0]), int(topLeft[1]))\n",
    "                    # draw lines around the marker and display the marker id\n",
    "                    cv2.line(video_frame, topLeft, topRight, (0, 255, 0), 2)\n",
    "                    cv2.line(video_frame, topRight, bottomRight, (0, 255, 0), 2)\n",
    "                    cv2.line(video_frame, bottomRight, bottomLeft, (0, 255, 0), 2)\n",
    "                    cv2.line(video_frame, bottomLeft, topLeft, (0, 255, 0), 2)                    \n",
    "                    cv2.putText(video_frame, str(id),(topLeft[0], topLeft[1] - 15), cv2.FONT_HERSHEY_SIMPLEX,0.5, (0, 255, 0), 2)\n",
    "                    corner = np.squeeze(Corner)\n",
    "                    refPts.append(corner)\n",
    "                    \n",
    "                    # only when all the 4 markes are detected in the image\n",
    "                    if len(refPts)==4:\n",
    "                        ( refPtBR, refPtTR,refPtBL, refPtTL) = refPts\n",
    "                        video_pt = np.array([  refPtTL[3], refPtBL[3],refPtBR[2], refPtTR[3]])\n",
    "                       \n",
    "                        # grab the spatial dimensions of the  image and define the\n",
    "                        # transform matrix for the image in \n",
    "                        #top-left, top-right,bottom-right, and bottom-left order\n",
    "                        image_pt = np.float32([[0,0], [h,0], [h,w], [0,w]])\n",
    "                        \n",
    "                        # compute the homography matrix between the image and the video frame\n",
    "                        matrix, _ = cv2.findHomography( image_pt, video_pt)\n",
    "                        \n",
    "                        #warp the  image to video frame based on the homography\n",
    "                        warped  = cv2.warpPerspective(image, matrix, (video_frame.shape[1], video_frame.shape[0]))\n",
    "                        \n",
    "                        #Create a mask representing region to \n",
    "                        #copy from the warped image into the video frame.\n",
    "                        mask = np.zeros((imgH, imgW), dtype=\"uint8\")\n",
    "                        cv2.fillConvexPoly(mask, video_pt.astype(\"int32\"), (255, 255, 255),cv2.LINE_AA)\n",
    "                                                                    \n",
    "                        # give the source image a black border\n",
    "                        # surrounding it when applied to the source image,\n",
    "                        #you can apply a dilation operation\n",
    "                        rect = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "                        mask = cv2.dilate(mask, rect, iterations=2)\n",
    "                        \n",
    "                        # Copy the mask with the three channel version by stacking it depth-wise,\n",
    "                        # This will allow copying the warped source image into the input image\n",
    "                        maskScaled = mask.copy() / 255.0\n",
    "                        maskScaled = np.dstack([maskScaled] * 3)\n",
    "                        \n",
    "                        # Copy the masked warped image into the video frame by\n",
    "                        # (1) multiplying the warped image and masked together, \n",
    "                        # (2) multiplying the Video frame with the mask \n",
    "                        # (3) adding the resulting images\n",
    "                        warpedMultiplied = cv2.multiply(warped.astype(\"float\"), maskScaled)\n",
    "                        imageMultiplied = cv2.multiply(video_frame.astype(float), 1.0 - maskScaled)\n",
    "                        #imgout = video frame multipled with mask \n",
    "                        #        + warped image multipled with mask\n",
    "                        output = cv2.add(warpedMultiplied, imageMultiplied)\n",
    "                        output = output.astype(\"uint8\")\n",
    "                        cv2.imshow(\"output\", output)\n",
    "    \n",
    "    ret, video_frame=video.read()\n",
    "    key = cv2.waitKey(20)\n",
    "    # if key q is pressed then break \n",
    "    if key == 113:\n",
    "        break \n",
    "    \n",
    "#finally destroy/close all open windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33184612fe23ea789693bd8266f7c5cf5860109e6e433b1efdda378c5f430ce8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
